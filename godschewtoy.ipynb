{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-api-python-client in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (2.129.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from google-api-python-client) (2.19.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from google-api-python-client) (2.29.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.63.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.6)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting youtube_transcript_api\n",
      "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: requests in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from youtube_transcript_api) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from requests->youtube_transcript_api) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from requests->youtube_transcript_api) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from requests->youtube_transcript_api) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joycelu/Library/Python/3.9/lib/python/site-packages (from requests->youtube_transcript_api) (3.3.2)\n",
      "Installing collected packages: youtube-transcript-api\n",
      "\u001b[33m  WARNING: The script youtube_transcript_api is installed in '/Users/joycelu/Library/Python/3.9/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  NOTE: The current PATH contains path(s) starting with `~`, which may not be expanded by all applications.\u001b[0m\n",
      "Successfully installed youtube-transcript-api-0.6.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joycelu/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect To YouTube Data API to Retrieve Top 3 Videos Related to Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V_2_5vi71qc', 'Gbjwbq_ur_g', '-ito6YDA1N0']\n"
     ]
    }
   ],
   "source": [
    "API_KEY = 'REDACTED_API'\n",
    "CHANNEL_NAME = 'YahooFinance'\n",
    "\n",
    "base_url = \"https://www.googleapis.com/youtube/v3\"\n",
    "\n",
    "# 1. Retrieve Channel ID\n",
    "def get_channel_id(channel_name):\n",
    "    url = f\"{base_url}/channels\"\n",
    "    params = {\n",
    "        'part': 'id',\n",
    "        'forHandle': channel_name,\n",
    "        'key': API_KEY\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status() \n",
    "    data = response.json()\n",
    "    \n",
    "    if 'items' in data and len(data['items']) > 0:\n",
    "        return data['items'][0]['id']\n",
    "    else:\n",
    "        raise ValueError(f\"No channel found: {channel_name}\")\n",
    "\n",
    "# 2: Get Top 3 Videos' IDs\n",
    "def get_top_videos(channel_id, query, max_results=3):\n",
    "    url = f\"{base_url}/search\"\n",
    "    params = {\n",
    "        'part': 'snippet',\n",
    "        'channelId': channel_id,\n",
    "        'q': query,\n",
    "        'maxResults': max_results,\n",
    "        'type': 'video',\n",
    "        'key': API_KEY\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status() \n",
    "    data = response.json()\n",
    "    video_ids = [item['id']['videoId'] for item in data['items']]\n",
    "    return video_ids\n",
    "\n",
    "try:\n",
    "    channel_id = get_channel_id(CHANNEL_NAME)\n",
    "    company_name = 'Google'\n",
    "    video_ids = get_top_videos(channel_id, company_name)\n",
    "    print(video_ids)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Transcript through Youtube Transcript API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(video_id):\n",
    "        lines = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        return [line['text'] for line in lines]\n",
    "\n",
    "def preprocess_transcript(transcript):\n",
    "    # Split transcript into segments of 5 lines each\n",
    "    new_lst = []\n",
    "    for i in range(0, len(transcript), 5):\n",
    "        lines = transcript[i:i+5]\n",
    "        into_one = ' '.join(lines)\n",
    "        new_lst.append(into_one)\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['welcome back to the watch list',\n",
       " 'semiconductors really were driving the',\n",
       " 'market there was a time when the semis',\n",
       " 'were up the market was up semis were',\n",
       " 'down the market was down and we',\n",
       " 'certainly seen some great names run up',\n",
       " \"but they've since pulled back and so now\",\n",
       " 'the question becomes what part of this',\n",
       " 'group are winners are they all winners',\n",
       " \"let's bring our panel and Michael\",\n",
       " 'Robinson Chief technology strategist at',\n",
       " 'Weiss ratings and Olivier blon shards',\n",
       " 'with us research director at futurum',\n",
       " 'group thank you both for being with us I',\n",
       " \"mean I think there's an idea that semi\",\n",
       " 'certainly can lead the market um you',\n",
       " 'know just saw an article on Nvidia',\n",
       " 'saying that Nvidia was still a',\n",
       " 'no-brainer when it comes to investing',\n",
       " 'Michael what do you',\n",
       " 'think well Nvidia is one of the great',\n",
       " \"chip companies of all time it's just\",\n",
       " \"been an amazing player um you've got a\",\n",
       " 'kind of a bifurcated Market as it were',\n",
       " 'uh a lot of the rally and Chip stocks',\n",
       " 'that were really heavily focused on the',\n",
       " \"electric vehicle Market you've seen that\",\n",
       " \"sort of slow down investors aren't as\",\n",
       " 'enthusiastic as they were say six months',\n",
       " 'ago we have this uh build out',\n",
       " 'shipped in the market for cars',\n",
       " 'Automotive chips are going to remain',\n",
       " 'hugely important and nxp as long and on',\n",
       " 'sem conductor are both players in there',\n",
       " 'but so that sort of cooled the growth',\n",
       " 'outlook for some of these stocks that',\n",
       " 'were heavy uh heavily invested in',\n",
       " \"electric vehicles and we've seen kind of\",\n",
       " 'Nvidia in some way suck some of the',\n",
       " \"oxygen out of the room because it's all\",\n",
       " 'been about Ai and not as much about',\n",
       " \"Automotive but if we don't have a\",\n",
       " 'healthy Automotive sector in the United',\n",
       " \"States and globally we don't have a\",\n",
       " 'healthy economy so for the long H right',\n",
       " \"it's a great Market to be in\",\n",
       " \"semiconductors if you've been following\",\n",
       " \"Nvidia for a while you'd know that the\",\n",
       " 'stock has been on an epic run recently',\n",
       " 'in fact it has skyrocketed in the last',\n",
       " 'few years as the company established',\n",
       " 'itself as the dominant force in gpus',\n",
       " 'accelerated Computing and AI as you',\n",
       " 'might already know the market for',\n",
       " \"generative AI is massive and it's\",\n",
       " 'actually expected to become a $1.3',\n",
       " \"trillion Market in just8 years it's\",\n",
       " 'obvious which company will benefit the',\n",
       " 'most from this explosive growth and that',\n",
       " 'is the market leader Nvidia many',\n",
       " 'analysts agree that Nvidia has more room',\n",
       " 'to grow even as competition rises from',\n",
       " 'both traditional chip makers and new',\n",
       " 'entrance because Nvidia has built an',\n",
       " 'ecosystem that is hard to replicate and',\n",
       " 'this could be just the beginning of',\n",
       " \"nvidia's dominance as it looks to define\",\n",
       " \"the future of computing that's what\",\n",
       " 'melus research analyst Ben riters wrote',\n",
       " \"in a recent note so let's take a look at\",\n",
       " 'what he had to say but before we do that',\n",
       " \"if you want to keep up with nvidia's\",\n",
       " 'latest updates and keep up with the',\n",
       " \"stock market's latest news you can\",\n",
       " 'follow our Twitter account we post',\n",
       " 'multiple times daily about the biggest',\n",
       " 'changes in catalysts in the market so',\n",
       " \"click the follow button if you don't\",\n",
       " 'want to miss the newest Market updates',\n",
       " \"now back to today's video our next guest\",\n",
       " \"believes the AI spending Trend well it's\",\n",
       " 'going to continue Matt Bryson WB',\n",
       " 'Security senior vice president of equity',\n",
       " 'research and Hardware joins us now has a',\n",
       " 'Buy on Nvidia price Target an even',\n",
       " 'thousand UH 60 minutes does a great job',\n",
       " 'of informing people',\n",
       " 'about things that you know about Nvidia',\n",
       " \"perhaps that so many don't know about\",\n",
       " 'not our audience they know plenty so',\n",
       " \"let's forget about that and just talk\",\n",
       " \"about last week's news that was more\",\n",
       " 'important for our audience which is',\n",
       " 'namely alphabet Microsoft meta those',\n",
       " 'capex numbers were enormous Matt what',\n",
       " 'does it mean for NVIDIA when you look',\n",
       " 'through those numbers in terms of how',\n",
       " 'much of that spend ends up with that',\n",
       " 'company',\n",
       " 'look these large data center um',\n",
       " 'operators have been spending more and',\n",
       " 'more on AI as a percentage of their',\n",
       " \"capex now they're telling you they're\",\n",
       " 'going to spend more in capex and that a',\n",
       " \"lot of that's going to be devoted to AI\",\n",
       " 'um Nvidia said multiple times that the',\n",
       " 'cloud is more than 50% of their spend I',\n",
       " 'think if you had social media in there',\n",
       " \"you're probably talking more than 2third\",\n",
       " 'of their spend um and so if those large',\n",
       " 'consumers are going to spend more that',\n",
       " \"that's a great thing for NVIDIA yeah I\",\n",
       " 'mean so where how do you model it out I',\n",
       " 'mean I I can go through I think of Tesla',\n",
       " \"and what they're going to spend not to\",\n",
       " \"mention even musk's xai startup which is\",\n",
       " 'Raising billions to basically spend in',\n",
       " 'in the data center so to speak and on',\n",
       " 'and on from there uh is the market',\n",
       " 'justified in sort of the current',\n",
       " 'multiple on this stock and or even',\n",
       " 'should it be higher given the potential',\n",
       " 'it',\n",
       " 'has yeah I Nvidia from multiple',\n",
       " \"perspective isn't crazy expensive um so\",\n",
       " 'the last time we downgraded Nvidia it',\n",
       " 'was because it was getting close to 50',\n",
       " 'times',\n",
       " 'which you have to go back to Cisco in in',\n",
       " '2000 at the peak of the internet bubble',\n",
       " 'to have that type of valuation',\n",
       " 'historically for such a large company',\n",
       " 'now from an earnings perspective um if I',\n",
       " 'remember correctly my multiple is based',\n",
       " 'on a little over 30 times Nvidia there',\n",
       " \"Lots historically so I don't think it's\",\n",
       " 'expensive um I I think rather the',\n",
       " 'question is at some point do we get a',\n",
       " 'pause in investment uh because some of',\n",
       " \"the promises of AI haven't shown up yet\",\n",
       " \"I don't think that's happening this year\",\n",
       " \"I don't think it's happening through\",\n",
       " \"Blackwell so we're a year plus out from\",\n",
       " 'that being risk in my view in a recent',\n",
       " \"research note analyst Ben rit's of melus\",\n",
       " 'research offered a positive outlook on',\n",
       " 'Nvidia stock his note basically said',\n",
       " 'sometimes a no brainer is a no-brainer',\n",
       " 'as he argued that Nvidia is well',\n",
       " 'positioned for significant growth due to',\n",
       " 'the increased spending on AI',\n",
       " 'infrastructure by Major cloud computing',\n",
       " 'companies rates points out that',\n",
       " 'companies like Amazon meta and Microsoft',\n",
       " 'are rapidly ramping up investments in AI',\n",
       " \"chips for data center projects if you've\",\n",
       " 'been following any of these companies',\n",
       " \"you'd know that he's absolutely right\",\n",
       " 'just last year Tech Giants Microsoft and',\n",
       " \"meta each spent $9 billion on nvidia's\",\n",
       " 'AIG gpus which indicates the great',\n",
       " 'demand for NVIDIA products another',\n",
       " 'magnificent 7 member is also very',\n",
       " \"interested in Nvidia chips and that's\",\n",
       " \"Tesla in the company's q1 earnings call\",\n",
       " 'CEO Elon Musk said that Tesla plans on',\n",
       " 'buying around 50,000 h100 chips from',\n",
       " 'Nvidia this year and since one chip',\n",
       " 'costs around',\n",
       " '$40,000 this alone could bring Nvidia',\n",
       " 'and extra $2 billion in Revenue so Cloud',\n",
       " 'providers and AI leaders are eager to',\n",
       " 'secure more Nvidia chips leading rates',\n",
       " 'to believe that the growth trajectory',\n",
       " 'for NVIDIA is compelling given its',\n",
       " 'strategic position in both Ai and cloud',\n",
       " 'computing still rates has acknowledged',\n",
       " 'that the stock may look expensive now',\n",
       " 'but he contends that Nvidia warrants a',\n",
       " \"premium given that the company's total\",\n",
       " 'addressable Market is huge in fact',\n",
       " 'Nvidia said in its latest earnings call',\n",
       " 'that the total addressable market for',\n",
       " 'data center chips is expected to grow',\n",
       " 'from $250 billion this year to 500',\n",
       " \"billion in 5 years reit's present a\",\n",
       " 'firmly bullish case that Nvidia is a',\n",
       " 'standout opportunity and even called it',\n",
       " 'stock and Nob brainer investment but',\n",
       " 'what does that mean for Nvidia stock',\n",
       " \"investors let's find out hello everyone\",\n",
       " 'and welcome back to investor',\n",
       " \"for Ritz's bullish sentiment towards\",\n",
       " 'Nvidia is reflected in his decision to',\n",
       " \"maintain a buy rating on the company's\",\n",
       " 'stock while raising his price Target to',\n",
       " '1,000 one',\n",
       " '$125 up from $1,000 let those numbers',\n",
       " \"sink in we're talking about a potential\",\n",
       " \"30% rise from nvidia's current perch\",\n",
       " 'around',\n",
       " '$864 so Rees is all in on the Nvidia',\n",
       " 'hike train picking up speed of course',\n",
       " 'investors have to wait until May 22 for',\n",
       " \"nvidia's earnings to see how it\",\n",
       " 'performed for the quarter but one',\n",
       " \"thing's for sure nvidia's earnings will\",\n",
       " 'be Stellar thanks to all the big Tech',\n",
       " 'names still buying its chips and with',\n",
       " \"the upcoming release of nvidia's most\",\n",
       " 'powerful chips for AI the Blackwell',\n",
       " 'chips these companies will likely keep',\n",
       " 'buying more to get their hands on the',\n",
       " 'newest Tech which will help them develop',\n",
       " 'even better AI models forget typical AI',\n",
       " 'these Cloud Giants are chasing AI or',\n",
       " \"artificial general intelligence we're\",\n",
       " 'talking about software that can reason',\n",
       " 'think creatively even attain',\n",
       " 'Consciousness like a human mind',\n",
       " 'extraordinary right s and we just heard',\n",
       " \"from Google or alphabet so we we'll\",\n",
       " 'start there with what sunai had to say I',\n",
       " 'want to go to you first I mean you hear',\n",
       " 'these comments on the earnings call how',\n",
       " 'does that change your thesis your way of',\n",
       " 'thinking around this name and uh your',\n",
       " 'own kind of rating that you have on',\n",
       " 'it yeah absolutely and and remember I',\n",
       " 'cover Microsoft so I can kind of talk',\n",
       " 'about that and then maybe bro more',\n",
       " 'broadly on AI but look the commentary',\n",
       " 'out of both Google and Microsoft I think',\n",
       " 'tells us that there is real demand for',\n",
       " \"AI and you know it's happening kind of\",\n",
       " 'at the data and infrastructure layer for',\n",
       " \"right now but what's really happening is\",\n",
       " \"there's be there's actual money being\",\n",
       " \"put behind this it's not just hype it's\",\n",
       " 'not just uh you know people talking',\n",
       " \"about it there's actual Capital being\",\n",
       " 'put to work look at uh you know',\n",
       " 'Microsoft where they said about 7% of',\n",
       " 'growth from Azure came from AI that',\n",
       " 'implies that AI is already a $4 billion',\n",
       " 'do AR business for Microsoft today and',\n",
       " \"that's not even counting any benefits\",\n",
       " \"that we're going to see from Office\",\n",
       " 'co-pilot so really I think this is just',\n",
       " 'speaking of the fact that although it is',\n",
       " 'very early days for generative AI there',\n",
       " 'is real interest and real Capital being',\n",
       " 'put to work with this T what do you',\n",
       " 'think do you agree that this AI',\n",
       " 'narrative now is back on track and back',\n",
       " 'in favor for investors following these',\n",
       " 'two',\n",
       " 'results uh first of all thanks for',\n",
       " 'having me and I do agree I do agree with',\n",
       " 'your guest um we are going through',\n",
       " 'really a',\n",
       " 'generational uh infrastructure build',\n",
       " 'with right now a lot of semiconductors a',\n",
       " 'lot of Hardware a lot of networking as',\n",
       " 'that geni stack gets built out um so',\n",
       " \"we're seeing these capex numbers if you\",\n",
       " 'look at where Google spent last uh this',\n",
       " 'last print it was $12 billion Microsoft',\n",
       " 'uh capex was $4',\n",
       " 'billion um they are spending a ton of',\n",
       " 'money on infrastructure and what gives',\n",
       " 'them both the advantage is their data',\n",
       " 'set or footprint already exists and um',\n",
       " 'their internal um uh expertise in',\n",
       " \"generative AI they're hitting it from a\",\n",
       " 'little bit different uh tax with',\n",
       " 'Microsoft uh investing in open Ai and',\n",
       " 'Google has a lot of internal gen AI',\n",
       " 'through deep mind so both are',\n",
       " 'Juggernauts and uh this Market is just',\n",
       " 'starting right now on the infrastructure',\n",
       " 'side and and soon we translate in the',\n",
       " 'software layer probably in 25 on the',\n",
       " 'Enterprise side AGI would change',\n",
       " 'everything about how we view AI right',\n",
       " 'now and AI companies like Microsoft and',\n",
       " 'open AI are doing everything they can to',\n",
       " 'be able to reach it however the',\n",
       " 'computing power required is is',\n",
       " \"unprecedented that's where Nvidia swoops\",\n",
       " 'in its state-of-the-art gpus are',\n",
       " 'especially designed to handle the',\n",
       " 'intense parallel processing needs of',\n",
       " 'deep Lenny models and as the AI',\n",
       " 'workloads grow ever more complex on the',\n",
       " 'path to AGI so too will the demand for',\n",
       " \"nvidia's specialized products many\",\n",
       " 'analysts and investors alike think that',\n",
       " \"nvidia's dominance will come to an end\",\n",
       " 'as Cloud companies like Amazon and',\n",
       " 'Microsoft are now making their own chips',\n",
       " 'but this is very unlikely because',\n",
       " \"nvidia's chips are still the best in the\",\n",
       " 'market and these companies still being',\n",
       " \"nvidia's customers even after they\",\n",
       " 'developed their own chips proves that',\n",
       " 'also it might be harder for them to',\n",
       " 'convince their customers to switch to',\n",
       " 'their internally developed 8i chips as',\n",
       " 'most of them would be already used to',\n",
       " 'Nvidia platforms Nvidia is particularly',\n",
       " 'entrenched in the inference phase of AI',\n",
       " 'when models make predictions on new data',\n",
       " \"reit's argues Nidia will remain the\",\n",
       " 'leader for supporting this demanding',\n",
       " 'realtime inference given its specialized',\n",
       " 'plat platforms for AI computation if you',\n",
       " 'made it this far into the video thank',\n",
       " 'you these videos take a lot of effort',\n",
       " 'and time to make so if you enjoyed them',\n",
       " 'please hit the like button and subscribe',\n",
       " 'to the channel this goes a long way in',\n",
       " 'helping us grow that said back to the',\n",
       " \"video and we haven't mentioned Invidia\",\n",
       " 'do you remember Nvidia do you remember',\n",
       " 'that I do I remember okay do you',\n",
       " 'remember the piece in 60 minutes was a',\n",
       " \"piece mostly about whether we'd all be\",\n",
       " 'taken over by robots yeah sure I will',\n",
       " \"tell you that here's a piece by UBS and\",\n",
       " \"it's talking about doll how much going\",\n",
       " 'to make uh earns per share to to 41',\n",
       " 'following supply chain 41 well David',\n",
       " \"this is a cheaper stock it's cheap stock\",\n",
       " \"and they're talking about shipment black\",\n",
       " 'for Blackwell in December now they think',\n",
       " \"that means there's going to be a product\",\n",
       " 'hole I think Blackwell ships earlier now',\n",
       " 'Blackwell is the big one uh that makes',\n",
       " 'it so that uh a lot of people feel they',\n",
       " \"can do video that's what I want when\",\n",
       " 'people think Blackwell they should be',\n",
       " 'thinking that you can in inject video',\n",
       " 'and then when you want to do inference',\n",
       " 'it will be a to do the video for it and',\n",
       " \"that's a rather remarkable thing right\",\n",
       " \"now we're very good at commands at words\",\n",
       " 'when we get video going wow what does',\n",
       " 'that mean what do you what are you',\n",
       " 'actually saying so you you okay so you',\n",
       " 'want you want your robot to',\n",
       " 'act uh like Daniel Craig in bond well it',\n",
       " \"will watch Daniel Craig and he'll and\",\n",
       " \"it'll do it it'll do it it'll do it and\",\n",
       " 'I think that what happens when you see',\n",
       " 'that is wait a second how did it do that',\n",
       " \"well it just ingested video it's no\",\n",
       " 'longer just print I mean right now it',\n",
       " 'can be Moby Dick in a second big deal',\n",
       " 'but when you can put movies in David I',\n",
       " 'can project you to be Carrie Grant',\n",
       " 'really or John Garfield John Garfield is',\n",
       " 'the one that does come up more often',\n",
       " \"right but I'm just saying that video is\",\n",
       " 'the next Frontier and if you can be able',\n",
       " 'to make video uh and do things then you',\n",
       " \"can teach robots to do things that we've\",\n",
       " 'never believed robots will not talk like',\n",
       " 'this robots will talk hey how you doing',\n",
       " 'partner as large cloud computing',\n",
       " 'companies increasingly adopt artificial',\n",
       " \"intelligence their demand for nvidia's\",\n",
       " 'specialized AI chips will substantially',\n",
       " 'increase and Nvidia is set to profit',\n",
       " 'greatly from this especially as it gets',\n",
       " 'ready to launch its most powerful chips',\n",
       " \"for AI the Blackwell gpus now we don't\",\n",
       " 'have an official release date for them',\n",
       " 'but we might have a better idea on when',\n",
       " \"nvidia's Blackwell chips will be\",\n",
       " 'released according to UBS analyst',\n",
       " 'Timothy cury the Blackwell chips could',\n",
       " 'start shipping in December which is a',\n",
       " \"little later than ubs's original\",\n",
       " 'Assumption of October with test timeline',\n",
       " 'suggesting late November or December as',\n",
       " 'more likely that means Nvidia could have',\n",
       " 'a patch of slower growth in the October',\n",
       " \"quarter but that's not a reason to worry\",\n",
       " 'about the chip maker according to the',\n",
       " 'analyst because demand for its Flagship',\n",
       " 'h100s remains strong our cury maintained',\n",
       " 'a buy rating on the stock and raised his',\n",
       " 'Target price to',\n",
       " '$1,150 from',\n",
       " '$1,100 for NVIDIA the future looks as',\n",
       " \"bright as it can be that's the\",\n",
       " 'resounding verdict from analysts Ben',\n",
       " 'rates and Timothy aruri after their deep',\n",
       " \"dive into nvidia's operations Cloud\",\n",
       " 'Giants are locked in an innovation',\n",
       " 'Sprint and Nvidia looks set to provide',\n",
       " 'the high octane fuel as the industry',\n",
       " 'charges Full Speed Ahead into an AI',\n",
       " 'powered tomorrow Nvidia is prepared to',\n",
       " 'benefit thanks to its specialized gpus',\n",
       " 'with the likes of Amazon and Google',\n",
       " 'doubling down on AI to stay ahead of the',\n",
       " 'competition demand for NVIDIA chips is',\n",
       " 'soaring so for investors scanning The',\n",
       " 'Horizon for compelling opportunities',\n",
       " 'analysts shine a spotlight squarely on',\n",
       " 'Nvidia the company looks prepared for',\n",
       " 'the AI Obsession goups the tech Titans',\n",
       " 'and Cloud infrastructure but what do you',\n",
       " 'think about Nvidia stock is it a buy at',\n",
       " 'the current price let us know your',\n",
       " 'thoughts in the comments section and',\n",
       " \"don't forget to tell us what your\",\n",
       " 'valuation for NVIDIA is if you would',\n",
       " 'like to know what companies like Nvidia',\n",
       " 'have been up to these past few days go',\n",
       " 'ahead and click on the next video on',\n",
       " 'your screen see you there']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = get_transcript('INGJmZaxpGE')\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/mr8488/distilroberta-finetuned-financial-news-sentiment-analysis\"\n",
    "headers = {\"Authorization\": f\"Bearer {'REDACTED_API'}\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": lst[0],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(lst):\n",
    "    new_lst = []\n",
    "    for i in range(0, len(lst), 5):\n",
    "        lines = lst[i:i+5]\n",
    "        into_one = ' '.join(lines)\n",
    "        new_lst.append(into_one)\n",
    "    print(new_lst)\n",
    "    def get_sentiment(line):\n",
    "        res = query({\n",
    "            \"inputs\": line\n",
    "        })\n",
    "        print(res)\n",
    "        return res[0][0]\n",
    "    return [get_sentiment(line) for line in new_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'neutral', 'score': 0.8874624967575073}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcome back to the watch list semiconductors really were driving the market there was a time when the semis were up the market was up semis were down the market was down and we', \"certainly seen some great names run up but they've since pulled back and so now the question becomes what part of this group are winners are they all winners let's bring our panel and Michael\", \"Robinson Chief technology strategist at Weiss ratings and Olivier blon shards with us research director at futurum group thank you both for being with us I mean I think there's an idea that semi\", 'certainly can lead the market um you know just saw an article on Nvidia saying that Nvidia was still a no-brainer when it comes to investing Michael what do you', \"think well Nvidia is one of the great chip companies of all time it's just been an amazing player um you've got a kind of a bifurcated Market as it were uh a lot of the rally and Chip stocks\", \"that were really heavily focused on the electric vehicle Market you've seen that sort of slow down investors aren't as enthusiastic as they were say six months ago we have this uh build out\", 'shipped in the market for cars Automotive chips are going to remain hugely important and nxp as long and on sem conductor are both players in there but so that sort of cooled the growth', \"outlook for some of these stocks that were heavy uh heavily invested in electric vehicles and we've seen kind of Nvidia in some way suck some of the oxygen out of the room because it's all\", \"been about Ai and not as much about Automotive but if we don't have a healthy Automotive sector in the United States and globally we don't have a healthy economy so for the long H right\", \"it's a great Market to be in semiconductors if you've been following Nvidia for a while you'd know that the stock has been on an epic run recently in fact it has skyrocketed in the last\", \"few years as the company established itself as the dominant force in gpus accelerated Computing and AI as you might already know the market for generative AI is massive and it's\", \"actually expected to become a $1.3 trillion Market in just8 years it's obvious which company will benefit the most from this explosive growth and that is the market leader Nvidia many\", 'analysts agree that Nvidia has more room to grow even as competition rises from both traditional chip makers and new entrance because Nvidia has built an ecosystem that is hard to replicate and', \"this could be just the beginning of nvidia's dominance as it looks to define the future of computing that's what melus research analyst Ben riters wrote in a recent note so let's take a look at\", \"what he had to say but before we do that if you want to keep up with nvidia's latest updates and keep up with the stock market's latest news you can follow our Twitter account we post\", \"multiple times daily about the biggest changes in catalysts in the market so click the follow button if you don't want to miss the newest Market updates now back to today's video our next guest\", \"believes the AI spending Trend well it's going to continue Matt Bryson WB Security senior vice president of equity research and Hardware joins us now has a Buy on Nvidia price Target an even\", \"thousand UH 60 minutes does a great job of informing people about things that you know about Nvidia perhaps that so many don't know about not our audience they know plenty so\", \"let's forget about that and just talk about last week's news that was more important for our audience which is namely alphabet Microsoft meta those capex numbers were enormous Matt what\", 'does it mean for NVIDIA when you look through those numbers in terms of how much of that spend ends up with that company look these large data center um', \"operators have been spending more and more on AI as a percentage of their capex now they're telling you they're going to spend more in capex and that a lot of that's going to be devoted to AI\", \"um Nvidia said multiple times that the cloud is more than 50% of their spend I think if you had social media in there you're probably talking more than 2third of their spend um and so if those large\", \"consumers are going to spend more that that's a great thing for NVIDIA yeah I mean so where how do you model it out I mean I I can go through I think of Tesla and what they're going to spend not to\", \"mention even musk's xai startup which is Raising billions to basically spend in in the data center so to speak and on and on from there uh is the market justified in sort of the current\", \"multiple on this stock and or even should it be higher given the potential it has yeah I Nvidia from multiple perspective isn't crazy expensive um so\", 'the last time we downgraded Nvidia it was because it was getting close to 50 times which you have to go back to Cisco in in 2000 at the peak of the internet bubble', 'to have that type of valuation historically for such a large company now from an earnings perspective um if I remember correctly my multiple is based on a little over 30 times Nvidia there', \"Lots historically so I don't think it's expensive um I I think rather the question is at some point do we get a pause in investment uh because some of the promises of AI haven't shown up yet\", \"I don't think that's happening this year I don't think it's happening through Blackwell so we're a year plus out from that being risk in my view in a recent research note analyst Ben rit's of melus\", 'research offered a positive outlook on Nvidia stock his note basically said sometimes a no brainer is a no-brainer as he argued that Nvidia is well positioned for significant growth due to', 'the increased spending on AI infrastructure by Major cloud computing companies rates points out that companies like Amazon meta and Microsoft are rapidly ramping up investments in AI', \"chips for data center projects if you've been following any of these companies you'd know that he's absolutely right just last year Tech Giants Microsoft and meta each spent $9 billion on nvidia's\", \"AIG gpus which indicates the great demand for NVIDIA products another magnificent 7 member is also very interested in Nvidia chips and that's Tesla in the company's q1 earnings call\", 'CEO Elon Musk said that Tesla plans on buying around 50,000 h100 chips from Nvidia this year and since one chip costs around $40,000 this alone could bring Nvidia', 'and extra $2 billion in Revenue so Cloud providers and AI leaders are eager to secure more Nvidia chips leading rates to believe that the growth trajectory for NVIDIA is compelling given its', \"strategic position in both Ai and cloud computing still rates has acknowledged that the stock may look expensive now but he contends that Nvidia warrants a premium given that the company's total\", 'addressable Market is huge in fact Nvidia said in its latest earnings call that the total addressable market for data center chips is expected to grow from $250 billion this year to 500', \"billion in 5 years reit's present a firmly bullish case that Nvidia is a standout opportunity and even called it stock and Nob brainer investment but what does that mean for Nvidia stock\", \"investors let's find out hello everyone and welcome back to investor for Ritz's bullish sentiment towards Nvidia is reflected in his decision to maintain a buy rating on the company's\", \"stock while raising his price Target to 1,000 one $125 up from $1,000 let those numbers sink in we're talking about a potential 30% rise from nvidia's current perch\", \"around $864 so Rees is all in on the Nvidia hike train picking up speed of course investors have to wait until May 22 for nvidia's earnings to see how it\", \"performed for the quarter but one thing's for sure nvidia's earnings will be Stellar thanks to all the big Tech names still buying its chips and with the upcoming release of nvidia's most\", 'powerful chips for AI the Blackwell chips these companies will likely keep buying more to get their hands on the newest Tech which will help them develop even better AI models forget typical AI', \"these Cloud Giants are chasing AI or artificial general intelligence we're talking about software that can reason think creatively even attain Consciousness like a human mind\", \"extraordinary right s and we just heard from Google or alphabet so we we'll start there with what sunai had to say I want to go to you first I mean you hear these comments on the earnings call how\", 'does that change your thesis your way of thinking around this name and uh your own kind of rating that you have on it yeah absolutely and and remember I cover Microsoft so I can kind of talk', \"about that and then maybe bro more broadly on AI but look the commentary out of both Google and Microsoft I think tells us that there is real demand for AI and you know it's happening kind of\", \"at the data and infrastructure layer for right now but what's really happening is there's be there's actual money being put behind this it's not just hype it's not just uh you know people talking\", \"about it there's actual Capital being put to work look at uh you know Microsoft where they said about 7% of growth from Azure came from AI that implies that AI is already a $4 billion\", \"do AR business for Microsoft today and that's not even counting any benefits that we're going to see from Office co-pilot so really I think this is just speaking of the fact that although it is\", 'very early days for generative AI there is real interest and real Capital being put to work with this T what do you think do you agree that this AI narrative now is back on track and back', 'in favor for investors following these two results uh first of all thanks for having me and I do agree I do agree with your guest um we are going through', 'really a generational uh infrastructure build with right now a lot of semiconductors a lot of Hardware a lot of networking as that geni stack gets built out um so', \"we're seeing these capex numbers if you look at where Google spent last uh this last print it was $12 billion Microsoft uh capex was $4 billion um they are spending a ton of\", \"money on infrastructure and what gives them both the advantage is their data set or footprint already exists and um their internal um uh expertise in generative AI they're hitting it from a\", 'little bit different uh tax with Microsoft uh investing in open Ai and Google has a lot of internal gen AI through deep mind so both are Juggernauts and uh this Market is just', 'starting right now on the infrastructure side and and soon we translate in the software layer probably in 25 on the Enterprise side AGI would change everything about how we view AI right', \"now and AI companies like Microsoft and open AI are doing everything they can to be able to reach it however the computing power required is is unprecedented that's where Nvidia swoops\", 'in its state-of-the-art gpus are especially designed to handle the intense parallel processing needs of deep Lenny models and as the AI workloads grow ever more complex on the', \"path to AGI so too will the demand for nvidia's specialized products many analysts and investors alike think that nvidia's dominance will come to an end as Cloud companies like Amazon and\", \"Microsoft are now making their own chips but this is very unlikely because nvidia's chips are still the best in the market and these companies still being nvidia's customers even after they\", 'developed their own chips proves that also it might be harder for them to convince their customers to switch to their internally developed 8i chips as most of them would be already used to', \"Nvidia platforms Nvidia is particularly entrenched in the inference phase of AI when models make predictions on new data reit's argues Nidia will remain the leader for supporting this demanding\", 'realtime inference given its specialized plat platforms for AI computation if you made it this far into the video thank you these videos take a lot of effort and time to make so if you enjoyed them', \"please hit the like button and subscribe to the channel this goes a long way in helping us grow that said back to the video and we haven't mentioned Invidia do you remember Nvidia do you remember\", \"that I do I remember okay do you remember the piece in 60 minutes was a piece mostly about whether we'd all be taken over by robots yeah sure I will tell you that here's a piece by UBS and\", \"it's talking about doll how much going to make uh earns per share to to 41 following supply chain 41 well David this is a cheaper stock it's cheap stock and they're talking about shipment black\", \"for Blackwell in December now they think that means there's going to be a product hole I think Blackwell ships earlier now Blackwell is the big one uh that makes it so that uh a lot of people feel they\", \"can do video that's what I want when people think Blackwell they should be thinking that you can in inject video and then when you want to do inference it will be a to do the video for it and\", \"that's a rather remarkable thing right now we're very good at commands at words when we get video going wow what does that mean what do you what are you actually saying so you you okay so you\", \"want you want your robot to act uh like Daniel Craig in bond well it will watch Daniel Craig and he'll and it'll do it it'll do it it'll do it and I think that what happens when you see\", \"that is wait a second how did it do that well it just ingested video it's no longer just print I mean right now it can be Moby Dick in a second big deal but when you can put movies in David I\", \"can project you to be Carrie Grant really or John Garfield John Garfield is the one that does come up more often right but I'm just saying that video is the next Frontier and if you can be able\", \"to make video uh and do things then you can teach robots to do things that we've never believed robots will not talk like this robots will talk hey how you doing partner as large cloud computing\", \"companies increasingly adopt artificial intelligence their demand for nvidia's specialized AI chips will substantially increase and Nvidia is set to profit greatly from this especially as it gets\", \"ready to launch its most powerful chips for AI the Blackwell gpus now we don't have an official release date for them but we might have a better idea on when nvidia's Blackwell chips will be\", \"released according to UBS analyst Timothy cury the Blackwell chips could start shipping in December which is a little later than ubs's original Assumption of October with test timeline\", \"suggesting late November or December as more likely that means Nvidia could have a patch of slower growth in the October quarter but that's not a reason to worry about the chip maker according to the\", 'analyst because demand for its Flagship h100s remains strong our cury maintained a buy rating on the stock and raised his Target price to $1,150 from', \"$1,100 for NVIDIA the future looks as bright as it can be that's the resounding verdict from analysts Ben rates and Timothy aruri after their deep dive into nvidia's operations Cloud\", 'Giants are locked in an innovation Sprint and Nvidia looks set to provide the high octane fuel as the industry charges Full Speed Ahead into an AI powered tomorrow Nvidia is prepared to', 'benefit thanks to its specialized gpus with the likes of Amazon and Google doubling down on AI to stay ahead of the competition demand for NVIDIA chips is soaring so for investors scanning The', 'Horizon for compelling opportunities analysts shine a spotlight squarely on Nvidia the company looks prepared for the AI Obsession goups the tech Titans and Cloud infrastructure but what do you', \"think about Nvidia stock is it a buy at the current price let us know your thoughts in the comments section and don't forget to tell us what your valuation for NVIDIA is if you would\", 'like to know what companies like Nvidia have been up to these past few days go ahead and click on the next video on your screen see you there']\n",
      "[[{'label': 'neutral', 'score': 0.8241142630577087}, {'label': 'positive', 'score': 0.1052476167678833}, {'label': 'negative', 'score': 0.07063810527324677}]]\n",
      "[[{'label': 'neutral', 'score': 0.9360322952270508}, {'label': 'positive', 'score': 0.04519059136509895}, {'label': 'negative', 'score': 0.018777118995785713}]]\n",
      "[[{'label': 'neutral', 'score': 0.8890740275382996}, {'label': 'positive', 'score': 0.10291101038455963}, {'label': 'negative', 'score': 0.008014957420527935}]]\n",
      "[[{'label': 'neutral', 'score': 0.9246025085449219}, {'label': 'positive', 'score': 0.07082168012857437}, {'label': 'negative', 'score': 0.004575865808874369}]]\n",
      "[[{'label': 'neutral', 'score': 0.6294779777526855}, {'label': 'positive', 'score': 0.36601942777633667}, {'label': 'negative', 'score': 0.004502630792558193}]]\n",
      "[[{'label': 'negative', 'score': 0.5643512010574341}, {'label': 'neutral', 'score': 0.40969333052635193}, {'label': 'positive', 'score': 0.02595551125705242}]]\n",
      "[[{'label': 'neutral', 'score': 0.48955363035202026}, {'label': 'positive', 'score': 0.28131547570228577}, {'label': 'negative', 'score': 0.22913087904453278}]]\n",
      "[[{'label': 'neutral', 'score': 0.5132349133491516}, {'label': 'negative', 'score': 0.46112993359565735}, {'label': 'positive', 'score': 0.025635121390223503}]]\n",
      "[[{'label': 'neutral', 'score': 0.5864394307136536}, {'label': 'negative', 'score': 0.39306244254112244}, {'label': 'positive', 'score': 0.020498139783740044}]]\n",
      "[[{'label': 'positive', 'score': 0.9622235298156738}, {'label': 'neutral', 'score': 0.03602892905473709}, {'label': 'negative', 'score': 0.0017474861815571785}]]\n",
      "[[{'label': 'neutral', 'score': 0.6960752010345459}, {'label': 'positive', 'score': 0.29994577169418335}, {'label': 'negative', 'score': 0.003979082684963942}]]\n",
      "[[{'label': 'positive', 'score': 0.5388379693031311}, {'label': 'neutral', 'score': 0.45802879333496094}, {'label': 'negative', 'score': 0.0031332725193351507}]]\n",
      "[[{'label': 'positive', 'score': 0.7911582589149475}, {'label': 'neutral', 'score': 0.20195728540420532}, {'label': 'negative', 'score': 0.0068844337947666645}]]\n",
      "[[{'label': 'neutral', 'score': 0.708467960357666}, {'label': 'positive', 'score': 0.28522101044654846}, {'label': 'negative', 'score': 0.00631094491109252}]]\n",
      "[[{'label': 'neutral', 'score': 0.9773963689804077}, {'label': 'positive', 'score': 0.018755238503217697}, {'label': 'negative', 'score': 0.003848383668810129}]]\n",
      "[[{'label': 'neutral', 'score': 0.9688763618469238}, {'label': 'positive', 'score': 0.026338187977671623}, {'label': 'negative', 'score': 0.004785511642694473}]]\n",
      "[[{'label': 'positive', 'score': 0.8868260979652405}, {'label': 'neutral', 'score': 0.107488252222538}, {'label': 'negative', 'score': 0.005685610696673393}]]\n",
      "[[{'label': 'neutral', 'score': 0.9364416599273682}, {'label': 'positive', 'score': 0.06024990603327751}, {'label': 'negative', 'score': 0.0033084468450397253}]]\n",
      "[[{'label': 'neutral', 'score': 0.49835923314094543}, {'label': 'positive', 'score': 0.4947751760482788}, {'label': 'negative', 'score': 0.0068655614741146564}]]\n",
      "[[{'label': 'neutral', 'score': 0.97867351770401}, {'label': 'positive', 'score': 0.01773523911833763}, {'label': 'negative', 'score': 0.0035912508610635996}]]\n",
      "[[{'label': 'neutral', 'score': 0.8778539299964905}, {'label': 'positive', 'score': 0.11653563380241394}, {'label': 'negative', 'score': 0.005610366817563772}]]\n",
      "[[{'label': 'neutral', 'score': 0.9732906222343445}, {'label': 'positive', 'score': 0.02283981442451477}, {'label': 'negative', 'score': 0.003869599662721157}]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_all(lst)\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36mget_all\u001b[0;34m(lst)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[39mprint\u001b[39m(res)\n\u001b[1;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m res[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m \u001b[39mreturn\u001b[39;00m [get_sentiment(line) \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m new_lst]\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[39mprint\u001b[39m(res)\n\u001b[1;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m res[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m \u001b[39mreturn\u001b[39;00m [get_sentiment(line) \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m new_lst]\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36mget_all.<locals>.get_sentiment\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_sentiment\u001b[39m(line):\n\u001b[0;32m----> 9\u001b[0m     res \u001b[39m=\u001b[39m query({\n\u001b[1;32m     10\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39minputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: line\n\u001b[1;32m     11\u001b[0m     })\n\u001b[1;32m     12\u001b[0m     \u001b[39mprint\u001b[39m(res)\n\u001b[1;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m res[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mquery\u001b[0;34m(payload)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquery\u001b[39m(payload):\n\u001b[0;32m----> 7\u001b[0m \tresponse \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mpost(API_URL, headers\u001b[39m=\u001b[39;49mheaders, json\u001b[39m=\u001b[39;49mpayload)\n\u001b[1;32m      8\u001b[0m \t\u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    468\u001b[0m     \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:1096\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[0;32m-> 1096\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1098\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[1;32m   1099\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1100\u001b[0m         (\n\u001b[1;32m   1101\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mconn\u001b[39m.\u001b[39mhost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1107\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m     sock: socket\u001b[39m.\u001b[39msocket \u001b[39m|\u001b[39m ssl\u001b[39m.\u001b[39mSSLSocket\n\u001b[0;32m--> 611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    612\u001b[0m     server_hostname: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[1;32m    613\u001b[0m     tls_in_tls \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \n\u001b[1;32m    200\u001b[0m \u001b[39m:return: New socket connection.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    204\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[1;32m    205\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m    206\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[1;32m    207\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    210\u001b[0m     \u001b[39mraise\u001b[39;00m NameResolutionError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m source_address:\n\u001b[1;32m     72\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m     74\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m     75\u001b[0m err \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_all(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
